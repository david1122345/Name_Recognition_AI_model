{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ddgCwwpWILW"
      },
      "outputs": [],
      "source": [
        "#get and tokenize names\n",
        "import os\n",
        "import pandas as pd # Import pandas as it's used later\n",
        "import numpy as np\n",
        "\n",
        "def tokenize_name(name, char_to_int, max_len=14):\n",
        "    if len(name) > max_len:\n",
        "        raise ValueError(f\"Name '{name}' is too long. Maximum length is {max_len}.\")\n",
        "    name = name.lower()\n",
        "    tokenized = [char_to_int.get(char, 0) for char in name] # Use 0 for unknown characters\n",
        "    # Pad or truncate to max_len\n",
        "    if len(tokenized) < max_len:\n",
        "        tokenized += [0] * (max_len - len(tokenized))\n",
        "    elif len(tokenized) > max_len:\n",
        "        tokenized = tokenized[:max_len]\n",
        "    return tokenized\n",
        "\n",
        "def one_hot_encode(tokenized_name, vocab_size):\n",
        "    encoded = np.zeros((len(tokenized_name), vocab_size))\n",
        "    for i, token in enumerate(tokenized_name):\n",
        "        if token != 0: # Don't one-hot encode padding (0)\n",
        "            encoded[i, token] = 1\n",
        "    return encoded.tolist()\n",
        "\n",
        "\n",
        "names_list = []\n",
        "# Use the built-in open() function instead of os.open()\n",
        "with open(\"/content/Popular_Baby_Names.csv\", \"r\") as f:\n",
        "    reader = pd.read_csv(f)\n",
        "    # Assuming the column with names is named 'Child's First Name' and gender is 'Gender'\n",
        "    # Adjust column names if necessary based on your CSV\n",
        "    # Create a vocabulary of all unique characters in the names\n",
        "    all_names = reader[\"Child's First Name\"].str.lower().str.cat()\n",
        "    chars = sorted(list(set(all_names)))\n",
        "    char_to_int = {char: i + 1 for i, char in enumerate(chars)} # Start indexing from 1, 0 for padding\n",
        "    vocab_size = len(chars) + 1 # +1 for padding\n",
        "\n",
        "    for index, row in reader.iterrows():\n",
        "        is_boy = 1 if row['Gender'] == 'MALE' else 0\n",
        "        name = row[\"Child's First Name\"]\n",
        "        tokenized = tokenize_name(name, char_to_int)\n",
        "        one_hot_encoded = one_hot_encode(tokenized, vocab_size)\n",
        "        names_list.append([is_boy, one_hot_encoded])\n",
        "\n",
        "\n",
        "df = pd.DataFrame(names_list, columns=[\"is_boy\",\"tokenized_name\"])\n",
        "\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "print(df.shape)\n",
        "display(df.head())\n",
        "\n",
        "test_df=df.sample(frac=0.2, random_state=42) # Added random_state for reproducibility\n",
        "df=df.drop(test_df.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCIBa4MjUnHJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "model=nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(14 * vocab_size, 512), # Changed input size to max_len * vocab_size (406)\n",
        "    nn.ReLU(),# this layer was origianlly 256\n",
        "    nn.Linear(512,1),\n",
        "    nn.Sigmoid() # Added Sigmoid for BCELoss\n",
        ")\n",
        "loss_fn=nn.BCELoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "epochs=250\n",
        "for i in range(epochs):\n",
        "  model.train() # Set model to training mode\n",
        "  # Convert pandas Series of lists to a PyTorch Tensor\n",
        "  # If using one-hot encoding, the shape is already (batch_size, sequence_length, vocab_size)\n",
        "  inputs = torch.tensor(df['tokenized_name'].tolist(), dtype=torch.float32) # No need to unsqueeze(2) if one-hot encoded\n",
        "  # Convert target to PyTorch Tensor\n",
        "  targets = torch.tensor(df['is_boy'].values, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "  y_pred=model(inputs)\n",
        "  loss=loss_fn(y_pred,targets) # Use targets instead of df['is_boy']\n",
        "  loss.backward() # Corrected from loss.back()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (i+1) % 10 == 0: # Print loss every epoch for this short training\n",
        "      print(f\"Epoch [{i+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"Training finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WY91kfHyezZC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def predict_gender(name, model, char_to_int, vocab_size, max_len=14):\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "    with torch.no_grad(): # Disable gradient calculation\n",
        "        # Tokenize the name (returns a list of integers)\n",
        "        tokenized_name = tokenize_name(name, char_to_int, max_len)\n",
        "        # One-hot encode the tokens\n",
        "        one_hot_encoded = one_hot_encode(tokenized_name, vocab_size)\n",
        "        # Convert the one-hot encoded list of lists to a PyTorch Tensor with batch dimension\n",
        "        # Shape will be (1, max_len, vocab_size)\n",
        "        input_tensor = torch.tensor([one_hot_encoded], dtype=torch.float32)\n",
        "\n",
        "        # Pass the tensor to the model\n",
        "        user_output = model(input_tensor)\n",
        "        # Get the probability (assuming the model output is a probability between 0 and 1)\n",
        "        probability = user_output.item()\n",
        "\n",
        "        # Determine the predicted class\n",
        "        predicted_class = \"Boy\" if probability > 0.5 else \"Girl\"\n",
        "\n",
        "        return predicted_class, probability\n",
        "\n",
        "# Interactive test\n",
        "while True:\n",
        "  try:\n",
        "    name_input = input(\"Enter a name to predict gender (or 'quit' to exit): \")\n",
        "    if name_input.lower() == 'quit':\n",
        "        break\n",
        "    if name_input:\n",
        "        # Pass the necessary arguments to the predict_gender function\n",
        "        predicted_gender, probability = predict_gender(name_input, model, char_to_int, vocab_size)\n",
        "        print(f\"Name: {name_input}, Predicted Gender: {predicted_gender}, Probability (Boy): {probability:.4f}\")\n",
        "    else:\n",
        "        print(\"Please enter a name.\")\n",
        "  except ValueError as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h4cn0Lw9zjgH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}